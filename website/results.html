<!DOCTYPE HTML>
<!--
	Photon by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Absolute quantification of mtDNA</title>
		<link rel="shortcut icon" href="diagrams/title-icon.ico">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->

		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/custom.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body>
			<nav class="navbar navbar-default navbar-fixed-top navbar-inverse">
			  <div class="container-fluid">
			  <ul class="nav navbar-nav navbar-left">
			  	<li><a href="index.html#landing_page">
			  		<i class="fa fa-line-chart fa-2x" aria-hidden="true"></i>
			  		</a>
			  	<li>
			  </ul>
	          <ul class="nav navbar-nav navbar-right">
		        <li><a href="index.html"><span>INTRO<span></a></li>
		        <li><a href="background.html"><span>BACKGROUND<span></a></li>
		        <li><a href="model.html"><span>MODEL<span></a></li>
		        <li><a href="inference.html"><span>INFERENCE<span></a></li>
		        <li><a href="results.html"><span>RESULTS<span></a></li>
		        <li><a href="summary.html"><span>SUMMARY<span></a></li>
		        <li><a href="references.html"><span>REFERENCES<span></a></li>
			    <li><a href="glossary.html"><span>GLOSSARY</span></a></li>
		      </ul>
			  </div>
			</nav>

			<section id="zero" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>Results</h2>
							</header>
							<p>The inference method was performed on both experimental and in-silico simulated data. Below we discuss the performance of the inference by looking at indicative plots such as joint and marginal posteriors, trace plots or Bayesian credible intervals.</p>
						</div>
						<div class="6u 12u$(medium)">
							<h3>Experimental data</h3>
							<p>The experimental data consists of qPCR amplification curves in the form of arrays of fluorescence reads. Each amplification curve represents the observation data used to infer the initial quantity of a target analyte X<sub>0</sub> (number of mtDNA molecules in a single cell). The qPCR experiments are performed in parallel, with the contents of each target analyte being placed in a separate well.
							</p>
							<p>Each amplification curve from experimental data has a corresponding X<sub>0</sub> estimate obtained using the standard curve method. This value is used as an additional indicator for whether the inferred posterior distribution for X<sub>0</sub> is centered around to the true value of the parameter. However, this value obtained from the standard curve method is simply an estimate, and should not be treated as the true X<sub>0</sub>.</p>
						</div>
						<div class="6u$ 12u$(medium)">
							<h3>In-silico simulation data</h3>
							<p>We perform in-silico simulations to obtain an amplification curve given a parametrisation θ = [X<sub>0</sub>, r, σ], a known fluorescence coefficient α (which is not inferred) and a number of qPCR cycles n. The simulated process starts with X=X<sub>0</sub> molecules, and is updated by sampling from a Binomial distribution with probability r. The fluorescence reads F<sub>1:n</sub> are generated by adding noise sampled from a Gaussian distribution with variance σ (see <a href="model.html">Model</a>).
							</p>
							<p>The advantage of the in-silico data is that it allows us to compare the means and posterior distributions of all parameters X<sub>0</sub>, r, σ with the true values using simulated data F<sub>1:n</sub>.</p>
						</div>
					</div>
				</div>
			</section>

			<section id="one" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>Trade-off between X<sub>0</sub> and the efficiency r</h2>
							</header>
							<p>In the first instance, inference was performed on data from a single amplification curve. As discussed in <a href="inference.html">Inference</a>, the exponential phase is extracted from the amplification curve and only those fluorescence reads are used as observation data. For the first ~30 cycles, the background noise dominates over the fluorescence signal, which leaves only data from ~4-5 cycles being informative for the inference of X<sub>0</sub> and r, before significant saturation occurs and the assumption of r being a fixed parameter is clearly unreasonable.
							</p>
							<p>We found that this lack of information caused degeneracy in the inference of X<sub>0</sub> and r by inspecting the joint posterior of the two parameters (see below). The explanation for this phenomenon is that for a short fluorescence curve, a similar fluorescence curve can be obtained by increasing the efficiency r and lowering the quantity of the target analyte X<sub>0</sub> (and vice-versa). However, with more data from the "take-off" part of the curve, there would be more information to distinguish between X<sub>0</sub> and r.
							</p>
							<p>The solution to this problem was to perform parameter-pooling inference using the data from multiple wells, with the assumption that parameters r and σ are shared between different wells within the same experimental setting. The new parameter for inference became θ = [X<sub>0</sub><sup>1</sup>, X<sub>0</sub><sup>2</sup>, X<sub>0</sub><sup>3</sup>, r, σ] for joint inference on 3 wells. Using data from multiple fluorescence curves where r is constant results in a more accurate inference of r, which in turn restricts the X<sub>0</sub><sup>j</sup> parameters. We see that the width of the marginals is strongly constrained through this alternative model structure.
							</p>
						</div>
						<br/>
						<div class="6u 12u$(medium) important(medium)">
							<div id="10_03_x0_p_sing_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium) important(medium)">
							<div id="10_03_x01_p_joint_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<figcaption><center><b>Figure 23.</b> Parameters X<sub>0</sub> and r can be traded off against each other (first plot), causing underdetermination in the marginals resulting from single-experiment inference (Fig. 25). When parameter pooling is used instead (second plot), the samples for X<sub>0</sub> and r are independent, which in turn gives more restricted (determined) marginal posteriors.
						</center></figcaption>
					</div>
				</div>
			</section>

			<section id="two" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>Marginal posterior distributions from real data</h2>
							</header>
							<p>We first look at results for the data obtained from real qPCR experiments. The goal of the inference method is to perform sampling from the joint posterior distribution P(θ | F<sub>1:n</sub>, α). The fluorescence coefficient α relates fluorescence intensity to molecule copy number and is determined prior to the inference, using sigmoid fitting on samples where the initial copy number X<sub>0</sub> is known. Sigmoid fitting was used instead of inference because these samples have large X<sub>0</sub> values, causing the process to behave deterministically (more details in <a href="model.html">Model</a>). The inference for P(θ | F<sub>1:n</sub>, α) produces a sequence of samples of θ that approximates the joint distribution. From this sequence we can extract samples for each component of θ (marginals) and plot the marginalised posterior distributions.</p>
							<p>It should be noted that posteriors shown here are merely indicative due to the analysis of chain mixing, which indicates that inference needs to be run for longer (see <a href="#mixing">Analysing the Markov chain</a>).
							</p>
							<p>
							The marginal posterior distributions are easy to visualize and encode all of our uncertainty in the parameter given the data. For the target analyte quantity X<sub>0</sub> we additionally plot the estimate from the standard curve method on top of the posterior distribution. The plot in Fig. 24 shows the posterior distributions obtained from joint inference using target analytes X<sub>0</sub><sup>1</sup>, X<sub>0</sub><sup>2</sup>, X<sub>0</sub><sup>3</sup> from 3 separate qPCR wells (253, 254, 255).
							</p>
							<div id="10_03_x0_all_marg_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<figcaption><center><b>Figure 24.</b> Marginal posteriors of copy numbers X<sub>0</sub><sup>i</sup> for different qPCR experiments (wells) are centered close to the values indicated by the standard curve method. However, this standard curve estimate should not be treated as the real parameter value.
							</center></figcaption>
						</div>
						<div class="12u$ 12u$(medium)">
							<br/>
							<p>The plots in Fig. 25 below demonstrate the effect of additional fluorescence data on the marginal posteriors by showing in parallel the results from single-well and joint inference. It is visible how the spread of posteriors narrows with joint inference, better localising the parameter values. Additionally, the prior used for each parameter is plotted: uniform prior for X<sub>0</sub>, Jeffreys priors for r and σ (the choice of priors discussed in <a href="inference.html#priors">Priors</a>).
						</div>

						<br/> 
						<div class="6u 12u$(medium)">
							<div id="10_03_x0_single_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium)">
							<div id="10_03_x01_marg_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>

						<div class="6u 12u$(medium)">
							<div id="10_03_p_single_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium)">
							<div id="10_03_p_marg_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<br/>

						<div class="6u 12u$(medium)">
							<div id="10_03_sigma_single_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium)">
							<div id="10_03_sigma_marg_results" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="12u$ 12u$(medium)">
						<figcaption><center><b>Figure 25.</b> Marginal posteriors of parameters X<sub>0</sub>, r, σ<sup>2</sup> shown in parallel for the single-experiment and parameter-pooling methods show how additional fluorescence information solves the trade-off problem between X<sub>0</sub> and r and narrows the marginals. The parameter pooling method shows a significant improvement in the error bar on estimates, and therefore in the credibility of estimates obtained from inference.
							</center></figcaption>
						</div>
						<br/>
					</div>
				</div>
			</section>

			<section id="three" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>Marginal posteriors distributions from simulated data</h2>
							</header>
							<p>In order to evaluate the inference method, we simulate a qPCR experiment in-silico and generate fluorescence data. We do so by choosing a true parameter to be the mean θ inferred from real data. An amplification curve is generated according to the random branching process model, using this fixed θ (for more details, see <a href="model.html">Model</a>). For brevity, we only look at results from the joint inference, as it has been shown in the previous section to remove parametric degeneracy.
							</p>
							<p>Testing the inference algorithm on in-silico simulated data allows the marginal posterior to be compared against a ground truth, the true parameter θ used to simulate the data, in order to check that the inference method works.
							</p>
							<div id="simulated_x0_marginal" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>

						<br/> 
						<div class="6u 12u$(medium)">
							<div id="simulated_p_marginal" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium)">
							<div id="simulated_sigma_marginal" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<figcaption><center>
							<b>Figure 26.</b> The marginal posteriors show that there is appreciable uncertainty in the quantity we are interested in, namely X<sub>0</sub>. This result motivates our model, as it is something not taken into account by the simpler standard curve method.
						</center></figcaption>
					</div>
				</div>
			</section>

			<section id="four" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>Stochasticity and uncertainty in fluorescence reads</h2>
							</header>
							<p>A main advantage of the Bayesian inference approach in qPCR absolute quantitation is that it accounts for both the stochasticity of the amplification process, by modelling it as a random branching process with efficiency r, as well as for parametric uncertainty. In this section, we show how stochasticity and parametric uncertainty result in a range of plausible fluorescence reads.</p>
							<p>The inference algorithm produces a sequence of θ samples that approximate sampling from the posterior distribution of θ. A qPCR experiment was simulated in-silico for each sample, resulting in a fluorescence read sequence. A 5%-95% confidence interval for the fluorescence reads across all simulated experiments was determined at each cycle. The plotted area (Fig. 27) shows the confidence interval for the fluorescence data (green). Additionally, the plot shows the real fluorescence data used for inference (red), as well as the mean fluorescence value at each cycle (blue).</p>
							</p>
							<div id="bci_zoomed" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<figcaption><center>
							<b>Figure 27.</b> The fluorescence curve has many plausible values due to the stochasticity inherent to the qPCR amplification and parameters not being known precisely (parametric uncertainty).
						</center></figcaption>
						</div>
					</div>
				</div>
			</section>


			<section id="five" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2>The effect of the fluorescence coefficient α on inference results</h2>
							</header>
							<!--
							<p>One of the main challenges of the project has been finding an appropriate way to treat the fluorescence coefficient α. Existing research [*quote] treats α as a fixed constant and do not discuss ways.
							</p>
							--><p>The inter- and intra-experimental variability of the fluorescence coefficient α were discussed in the <a href="model.html#coefficient-variability">Model</a> section and are showed again (Fig. 28). Estimates for α were obtained by fitting sigmoid curves on data from standards with known initial quantities X<sub>0</sub>. Sigmoid fitting was used instead of inference because these standards had a large copy number X<sub>0</sub>, causing the amplification process to behave deterministically. It has been discussed that the inter-experimental variability in α is explained by the use of different primers (experiments 3 and 4 below use the same primer and have a similar distribution). Thus the α estimate can be used for inference on a new sample, if the sample uses the same primer as the standards.</p>
							
							<div id="boxplot" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<figcaption><center>
							<b>Figure 28.</b> The fluorescence coefficient α estimates show significant inter-experimental variability when different primers are used. When the same primer is used, the distribution of α is very similar, although experiments were performed on different days. More work is needed to formally establish this result.
							</center></figcaption>
							<br>
							<p>
							 We are now interested in how different values of α from the same qPCR experimental setting influence the posterior distribution of X<sub>0</sub>, and how the initial copy number of the standard used for sigmoid fitting may play a role in the shape of the marginal posterior.
							</p>
							<p>The experiments used to estimate α have the following initial standard quantities: 3 wells with 100,000 molecules, 3 with 10,000 and 3 with 1,000. A total of 9 α estimates were obtained. The plots below (Fig. 29) show posteriors from inference runs with different α values, grouped by the initial number of molecules in the curve used to determine α. The inference results plotted in other sections of this page all use the mean value of α from estimates obtained with sigmoid-fitting.</p>
							</p>

							<div id="different_alphas_posteriors_100000" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<div id="different_alphas_posteriors_10000" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<div id="different_alphas_posteriors_1000" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
							<figcaption><center><b>Figure 29.</b> The larger variance of the posterior in the third plot can be explained by the deterministic behaviour assumption in sigmoid-fitting not holding when the standard inital copy number is too small, X<sub>0</sub> = 1,000 (details about role of copy number in stochasticity discussed in <a href="model.html#choice-of-model">Choice of model</a>). It is not evident why the marginal posterior is larger when the standard copy number is X<sub>0</sub> and further work is needed to explain this result.</center>
							</figcaption>
						</div>
					</div>
				</div>
			</section>

			<section id="six" class="main style1">
				<div class="container">
					<div class="row 150%">
						<div class="12u$ 12u$(medium)">
							<header class="major">
								<h2 id="mixing" style="margin-top:-70px; padding-top:70px">Analysing the Markov chain</h2>
							</header>
							<p>A Metropolis-Hastings algorithm produces a Markov chain of samples with the joint posterior P(θ | F<sub>1:n</sub>, α) as its stationary distribution. The calibration of the covariance Σ of the proposal distribution Q(θ’|θ) (see <a href="general-mh">General Metropolis-Hastings</a>) is essential for producing a chain with the desired properties. Two common ways of assessing the inference method and the covariance Σ are traceplots and auto-correlation functions (ACF). We first explain the meaning of traceplots by looking at different types of Markov chains, then show the traceplots for our inference.</p>
							<h3>Background</h3>
							<p>Three types of mixing behaviour may occur:
							<ul>
								<li>Chain is too cold — occurs when the covariance is too small, causing the samples to be correlated. The samples appear like a continuous trace on the joint posterior. The traceplot has fluctuations on the macroscopic level and the ACF fails to drop to zero (Fig. 30a).</li>
								<li>Chain is too hot — occurs when the covariance is too large, causing bad proposals and a low acceptance rate. The samples spend a long time in the same position on the joint posterior. The trace plot has a "Manhattan skyline effect" (Fig. 30b).</li>
								<li>Chain is well mixed — occurs when the covariance is appropriate, causing samples to appear independent and identically distributed when plotted onto the posterior. The trace plot has the "caterpillar effect" and the ACF quickly drops to zero (Fig. 30c).</li>
							</ul>
							</p> 
						</div>
						<div class="6u 12u$(medium)">
							<center><img src="diagrams/cold_traceplot.png" style="width:100%" alt="Cold chain"></center>
						</div>
						<div class="6u$ 12u$(medium)">
							<center><img src="diagrams/cold_posterior.png" style="width:100%" alt="Cold chain"></center>
						</div>
						<div class="12u$ 12u$(medium)">
						<figcaption><center><b>Figure 30a.</b> Example cold chain trace plot and joint posterior plot generated using a simple implementation of MH, used to fit two normal distributions with unknown means (the model parameters) and known fixed variance on 2D observation data. Only the trace plot of the first parameter is shown and its true value is plotted as a horizontal line. The chain is cold when the covariance of the proposal is too small, causing samples to be correlated.</center></figcaption>
						
						<br></div>

						<div class="6u 12u$(medium)">
							<center><img src="diagrams/hot_traceplot.png" style="width:100%" alt="Hot chain"></center>
						</div>
						<div class="6u$ 12u$(medium)">
							<center><img src="diagrams/hot_posterior.png" style="width:100%" alt="Hot chain"></center>
						</div>
						<div class="12u$ 12u$(medium)">
						<figcaption><center><b>Figure 30b.</b> Example hot chain trace plot ("Manhattan skyline") and joint posterior plot using the same algorithm and observation data as in Fig. 30a. The chain is hot when the covariance of the proposal is too large, causing bad proposals to be made and lowering the acceptance rate.</center></figcaption>
						
						<br></div>

						<div class="6u 12u$(medium)">
							<center><img src="diagrams/good_traceplot.png" style="width:100%" alt="Good chain"></center>
						</div>
						<div class="6u$ 12u$(medium)">
							<center><img src="diagrams/good_posterior.png" style="width:100%" alt="Good chain"></center>
						</div>
						<div class="12u$ 12u$(medium)">
						<figcaption><center><b>Figure 30c.</b> Example of well-mixing chain trace plot ("caterpillar plot") and joint posterior showing samples that are independent and identically distributed. The trace plot and joint posteriors shown here are the goals in terms of inference results.</center></figcaption>
						</div>
						<div class="12u$ 12u$(medium)">
							<h3>Mixing results</h3>
							<p>The chains for parameters X<sub>0</sub> and r look cold on the macroscopic level (Fig. 31), indicating that the inference may be exploring different regions of the parameter space that are comparable in terms of their log posterior value. Inference was run for only 100,000 iterations, with equally spread 10,000 samples shown here. Therefore, the posteriors shown above are only indicative results. Running the simulations for longer may allow chains to fully mix, and should be done as future work.</p>
							<!--<p>A trace plot shows the values of samples produced by the inference algorithm over the number of iterations. It provides information about some aspects of algorithm calibration: the number of iterations, the covariance of the proposal distribution or the burn-in. A well-calibrated algorithm forms a Markov-Chain of </p>
						-->
							<div id="mixing_x01" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u 12u$(medium)">
							<div id="mixing_p" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="6u$ 12u$(medium)">
							<div id="mixing_sigma" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="12u$ 12u$(medium)">

						<figcaption><center><b>Figure 31.</b> The trace plots for X<sub>0</sub> and r show that the chain is not fully mixed and iterations should be run for longer to allow the chain to fully mix.</center>
							</figcaption>
						<br>
						</div>
						<br/>
						<div class="4u 12u$(medium)">
							<div id="acf_x01" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="4u 12u$(medium)">
							<div id="acf_p" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="4u$ 12u$(medium)">
							<div id="acf_sigma" style="min-width: 310px; height: 400px; margin: 0 auto"></div>
						</div>
						<div class="12u$ 12u$(medium)">

						<figcaption><center><b>Figure 32.</b> The lag on the ACF plots for X<sub>0</sub> and r does not immediately drop to 0, showing that the samples are not independent. This indicates that further work is needed to improve the inference method.</center>
							</figcaption>
						</div>
					</div>
				</div>
			</section>


		<!-- Footer -->
			<section id="footer">
				<ul class="actions">
					<li><a href="summary.html" class="button scrolly">Read next section</a></li>
				</ul>
				<ul class="copyright">
					<li>© 2017 Daria Dicu</li>
					<li>Imperial College London</li>
					<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
				</ul>
			</section>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>
			<!-- High charts -->
			<script src="https://code.highcharts.com/highcharts.js"></script>
			 <script src="https://code.highcharts.com/highcharts-more.js"></script>
			<script src="https://code.highcharts.com/modules/exporting.js"></script>
			<script src="10_03_plots.js"></script>

	</body>
</html>